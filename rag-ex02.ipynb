{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c54542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. 문서 내용 읽고 분할 ########################################\n",
    "loader = Docx2txtLoader('law_1.docx')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "# 2. 임베딩 -> 벡터 데이터베이스에 저장 ######################################\n",
    "\n",
    "## 2-1 환경변수 읽어오기\n",
    "load_dotenv()\n",
    "\n",
    "## 2-2. 임베딩 모델 지정 \n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "\n",
    "\n",
    "## 2-3. 벡터 데이터베이스에 저장 \n",
    "## [방법 1] in memory\n",
    "# database = Chroma.from_documents(\n",
    "#     documents=document_list,\n",
    "#     embedding=embedding,\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175a7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ##[방법 2] 로컬에 저장\n",
    "# database = Chroma.from_documents(\n",
    "#     documents=document_list,\n",
    "#     embedding=embedding,\n",
    "#     persist_directory='./chroma',\n",
    "#     collection_name='chroma-law',\n",
    "# )\n",
    "\n",
    "# database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef77c0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x1bac59c7d90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 로컬에 저장된 임베딩 데이터 가져오기\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "database = Chroma(\n",
    "    collection_name='chroma-law',\n",
    "    persist_directory='./chroma',\n",
    "    embedding_function=embedding,\n",
    ")\n",
    "\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58203998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='전세사기피해자로 인정받기 위해서는 다음의 요건을 모두 갖추어야 합니다. 단, 경매 또는 공매 절차가 완료된 임차인의 경우에는 첫 번째 및 세 번째 요건은 제외됩니다.\\n\\n1. 주택임대차보호법 제3조에 따라 주택의 인도와 주민등록을 마치고, 같은 법 제3조의2 제2항에 따라 임대차계약증서상의 확정일자를 갖출 것. 임차권등기를 마친 경우 또는 민법 제303조에 따라 전세권이 설정된 경우도 포함됩니다.\\n\\n2. 임차인의 임차보증금이 5억원 이하일 것. 다만, 전세사기피해지원위원회가 시ㆍ도별 여건 및 피해자의 여건 등을 고려하여 임차보증금의 상한액을 2억원의 범위에서 상향 조정할 수 있습니다.\\n\\n3. 임대인의 파산 또는 회생절차 개시, 임차주택의 경매 또는 공매절차의 개시 등으로 인해 다수의 임차인에게 임차보증금 반환 채권의 변제를 받지 못하는 피해가 발생하였거나 발생할 것이 예상될 것.\\n\\n4. 임대인 등에게 수사가 개시되었거나, 임대인의 기망, 임차보증금을 반환할 능력이 없는 자에게 임차주택이 양도되었거나, 임차보증금을 반환할 능력 없이 다수의 주택을 취득ㆍ임대하여 임차보증금 반환채무를 이행하지 않을 의도가 있었다고 의심할 만한 상당한 이유가 있을 것.\\n\\n또한, 임차인이 임차보증금 반환을 위한 보증 또는 보험에 가입하여 보증금 전액 반환이 가능한 경우, 보증금 전액이 최우선 변제가 가능한 경우, 대항력 또는 우선변제권 행사를 통해 보증금 전액을 자력으로 회수할 수 있는 경우는 전세사기피해자로 인정받기 위한 요건에서 제외됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 458, 'prompt_tokens': 3139, 'total_tokens': 3597, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BduoZzcfsllOtt1aPRGCU8dHOQR78', 'finish_reason': 'stop', 'logprobs': None}, id='run--52b7c4dc-1470-4762-9803-a44822590a67-0', usage_metadata={'input_tokens': 3139, 'output_tokens': 458, 'total_tokens': 3597, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "## 3. 질문이 있으면, 벡터 데이터베이스에서 유사도 검색 ############################\n",
    "## 3-1. 사용자 질문\n",
    "query = '전세사기피해자로 인정받기 위한 조건은? '\n",
    "\n",
    "## 3-2. 벡터 데이터베이스에서 유사도 검색\n",
    "retrieved_docs = database.similarity_search(query=query, k=3)\n",
    "\n",
    "## 4. 유사도 검색으로 가져온 문서를 LLM에 질문과 같이 전달 #############################\n",
    "## 4-1 프롬프트 작성 \n",
    "prompt = '''\n",
    "[identity]\n",
    "- 당신은 전세사기피해 법률 전문가입니다.\n",
    "-[context]를 참고하여 사용자의 질문에 답변해주세요.\n",
    "\n",
    "[content]\n",
    "{retrieved_docs}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "'''\n",
    "## 4-2. 프롬프트 변수에 값 설정\n",
    "formatted_prompt = prompt.format(\n",
    "    retrieved_docs=retrieved_docs,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "## 4-3. LLM 모델 생성(chatOpenAI 인스턴스 생성)\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "## 4-4. LLM 모델에 질문과 검색된 문서를 보냄\n",
    "ai_message = llm.invoke(formatted_prompt)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d2bd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50cfe69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                         Type                              Data/Info\n",
      "----------------------------------------------------------------------------\n",
      "ChatOpenAI                       ModelMetaclass                    <class 'langchain_openai.<...>_models.base.ChatOpenAI'>\n",
      "Chroma                           ABCMeta                           <class 'langchain_chroma.vectorstores.Chroma'>\n",
      "Docx2txtLoader                   ABCMeta                           <class 'langchain_communi<...>document.Docx2txtLoader'>\n",
      "OpenAIEmbeddings                 ModelMetaclass                    <class 'langchain_openai.<...>s.base.OpenAIEmbeddings'>\n",
      "RecursiveCharacterTextSplitter   ABCMeta                           <class 'langchain_text_sp<...>veCharacterTextSplitter'>\n",
      "ai_message                       AIMessage                         content='전세사기피해자로 인정받기 위해<...>dio': 0, 'reasoning': 0}}\n",
      "database                         Chroma                            <langchain_chroma.vectors<...>ct at 0x000001BAC59C7D90>\n",
      "document_list                    list                              n=23\n",
      "embedding                        OpenAIEmbeddings                  client=<openai.resources.<...>embedding_ctx_length=True\n",
      "formatted_prompt                 str                               \\n[identity]\\n- 당신은 전세사기피<...>세사기피해자로 인정받기 위한 조건은? \\n\\n\n",
      "llm                              ChatOpenAI                        client=<openai.resources.<...>y=SecretStr('**********')\n",
      "load_dotenv                      function                          <function load_dotenv at 0x000001BAC5A02B00>\n",
      "loader                           Docx2txtLoader                    <langchain_community.docu<...>ct at 0x000001BAC59C6B60>\n",
      "prompt                           str                               \\n[identity]\\n- 당신은 전세사기피<...>\\n\\nQuestion: {query}\\n\\n\n",
      "query                            str                               전세사기피해자로 인정받기 위한 조건은? \n",
      "retrieved_docs                   list                              n=3\n",
      "text_splitter                    RecursiveCharacterTextSplitter    <langchain_text_splitters<...>ct at 0x000001BAC59C54E0>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9453a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
